lr-0.0001_bs-128: {train_loss: 0.08900160797770867, valid_loss: 0.1097168388748614}
lr-0.0001_bs-16: {train_loss: 0.1610909938482948, valid_loss: 0.11384453342632078}
lr-0.0001_bs-32: {train_loss: 0.12720130096088372, valid_loss: 0.11797567398460745}
lr-0.0001_bs-64: {train_loss: 0.10226206722955665, valid_loss: 0.10974048391864966}
lr-0.0005_bs-128: {train_loss: 0.017640491273105748, valid_loss: 0.08175727731701384}
lr-0.0005_bs-16: {train_loss: 0.07260632161632553, valid_loss: 0.07833538120584319}
lr-0.0005_bs-32: {train_loss: 0.04351482174625877, valid_loss: 0.07871650666571307}
lr-0.0005_bs-64: {train_loss: 0.027981987639268287, valid_loss: 0.08118313514453696}
lr-0.001_bs-128: {train_loss: 0.010105587747321296, valid_loss: 0.08423272815041084}
lr-0.001_bs-16: {train_loss: 0.05977725587870784, valid_loss: 0.0766820012781652}
lr-0.001_bs-32: {train_loss: 0.032663602366257094, valid_loss: 0.08179284552765748}
lr-0.001_bs-64: {train_loss: 0.017930742769569852, valid_loss: 0.07659194389881119}
lr-0.005_bs-128: {train_loss: 0.008452115894910224, valid_loss: 0.08852910236619313}
lr-0.005_bs-16: {train_loss: 0.054495065971770215, valid_loss: 0.07138362205332678}
lr-0.005_bs-32: {train_loss: 0.026166443038121375, valid_loss: 0.07259471155102432}
lr-0.005_bs-64: {train_loss: 0.013397837615164429, valid_loss: 0.07812676972036602}
lr-0.01_bs-128: {train_loss: 0.010238897235263373, valid_loss: 0.08831625832553748}
lr-0.01_bs-16: {train_loss: 0.056593698702248514, valid_loss: 0.07518586782280796}
lr-0.01_bs-32: {train_loss: 0.031581266012044834, valid_loss: 0.07493165400965676}
lr-0.01_bs-64: {train_loss: 0.015928471470997276, valid_loss: 0.08465835159778941}
